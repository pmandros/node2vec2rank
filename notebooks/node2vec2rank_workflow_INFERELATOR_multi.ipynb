{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import multiprocessing\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import copy \n",
    "\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grn_filenames = (\"../data/networks/inferelator/signed_network.tsv\",\n",
    "                 \"../data/networks/inferelator/CSTARVE_signed_network.tsv\") \n",
    "\n",
    "\n",
    "tissue = 'yeast'\n",
    "target = 'wildVScstarve'\n",
    "network_inf_method = 'INFERELATOR'\n",
    "gsea_parent_folder_name = \"INFERE_CSTARVE_UASE_n2v2r_crazy_abs\"\n",
    "\n",
    "\n",
    "\n",
    "#do the data have index and header??\n",
    "## if it is .csv, most likely the sep = \",\"\n",
    "#  if it is .tsv, most likely the sep = \"\\t\"\n",
    "index_col = 0\n",
    "header = 0\n",
    "sep = '\\t'\n",
    "\n",
    "\n",
    "#load the gene regulatory networks into PANDAS dataframes and then a list\n",
    "# the yeast inferelator data have TFs in columns, so we transpose to have them on rows ()\n",
    "grns = []\n",
    "for grn_filename in grn_filenames:\n",
    "    grn_pd = pd.read_csv(grn_filename,  index_col=index_col, header=header, sep=sep).T\n",
    "    grns.append(grn_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use commmon genes in case and control\n",
    "\n",
    "control = grns[0].copy()\n",
    "case = grns[1].copy()\n",
    "\n",
    "control_columns = control.columns.to_list()\n",
    "control_rows = control.index.to_list()\n",
    "\n",
    "case_columns = case.columns.to_list()\n",
    "case_rows = case.index.to_list()\n",
    "\n",
    "case_net_columns = grns[1].columns.to_list()\n",
    "case_net_rows = grns[1].index.to_list()\n",
    "\n",
    "genes_in_control_not_in_case = set(control_columns) - set(case_net_columns)\n",
    "genes_in_case_not_in_control = set(case_columns) - set(control_columns)\n",
    "\n",
    "common_cols = list(set(case_net_columns).intersection(control_columns))\n",
    "common_rows = list(set(case_net_rows).intersection(control_rows))\n",
    "\n",
    "case = case.loc[:,common_cols]\n",
    "control = control.loc[:,common_cols]\n",
    "\n",
    "case = case.loc[common_rows,:]\n",
    "control = control.loc[common_rows,:]\n",
    "\n",
    "grns[0] = control\n",
    "grns[1] = case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## network transformation and preparation for n2v2r\n",
    "## be mindful of the transformations and their consequences e.g., n2v2r does not accept negative weights\n",
    "\n",
    "from node2vec2rank.utils import network_transform\n",
    "\n",
    "row_genes = grns[0].index.to_numpy()\n",
    "col_genes = grns[0].columns.to_numpy()\n",
    "\n",
    "yeast_map_fn = '../data/gene_set_libraries/yeast/yeast_orf_to_symbol_mapping.tsv'\n",
    "yeast_map = pd.read_csv(yeast_map_fn, sep=\"\\t\")\n",
    "orf2symbol = {i['orf']:i['name'] for k,i in yeast_map.iterrows()}\n",
    "\n",
    "## use names for TFs to ensure all nodes have unique names (i.e., a TF and a gene having the same ORF will not be a problem)\n",
    "row_genes_name = [orf2symbol[x] for x in row_genes]\n",
    "\n",
    "total_genes = np.append(row_genes_name, col_genes)\n",
    "total_genes = np.unique(total_genes)\n",
    "\n",
    "num_rows = np.size(row_genes_name)\n",
    "num_cols = np.size(col_genes)\n",
    "num_total = np.size(total_genes)\n",
    "\n",
    "\n",
    "print(f\"There are {num_rows} row genes, {num_cols} column genes, and {num_total} unique in first (anchor) graph\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get DeDi \n",
    "## map gene ids to names if necessary\n",
    "\n",
    "control_net_adj = grns[0]\n",
    "case_net_adj =  grns[1] \n",
    "\n",
    "net_one_adj_indegree = control_net_adj.sum(axis=0).to_numpy()\n",
    "net_two_adj_indegree = case_net_adj.sum(axis=0).to_numpy()\n",
    "\n",
    "DeDi = net_one_adj_indegree - net_two_adj_indegree\n",
    "absDeDi = np.abs(DeDi)\n",
    "\n",
    "DeDi_genes_orf = control_net_adj.columns.to_list()\n",
    "\n",
    "# map orf to gene name\n",
    "yeast_map_fn = '../data/gene_set_libraries/yeast/yeast_orf_to_symbol_mapping.tsv'\n",
    "yeast_map = pd.read_csv(yeast_map_fn, sep=\"\\t\")\n",
    "orf2symbol = {i['orf']:i['name'] for k,i in yeast_map.iterrows()}\n",
    "DeDi_genes_name = [orf2symbol[x] for x in DeDi_genes_orf]\n",
    "\n",
    "DeDi_data_dict = {\"genes\" :DeDi_genes_name, \"DeDi\": DeDi, \"absDeDi\": absDeDi}\n",
    "\n",
    "DeDi_data_pd = pd.DataFrame(DeDi_data_dict, index=DeDi_genes_name)\n",
    "DeDi_data_pd.sort_values(by='absDeDi', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec2rank.model_multi import n2v2r\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "#read the config file\n",
    "config = json.load(open('../configs/config_infer_multi.json', 'r'))\n",
    "\n",
    "config = {param: value for section, params in config.items()\n",
    "          for param, value in params.items()}\n",
    "\n",
    "##the dictionary for mapping indices to gene names\n",
    "node_names = DeDi_genes_name\n",
    "\n",
    "model = n2v2r(graphs=grns, config=config, node_names=node_names)\n",
    "rankings = model.fit_transform_rank()\n",
    "\n",
    "borda_rankings = model.aggregate_transform()\n",
    "\n",
    "signed_rankings = model.signed_ranks_transform(DeDi_data_pd.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v2r_ranking_pd = rankings[0]\n",
    "n2v2r_borda_ranking_pd = borda_rankings[0]\n",
    "n2v2r_DeDi_ranking_pd = signed_rankings[0]\n",
    "n2v2r_borda_DeDi_ranking_pd = model.aggregate_signed_ranks_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec2rank.visualization_utils import dim_reduction, plot_embeddings\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "algorithm = 'umap'\n",
    "n_components = 3\n",
    "\n",
    "first_embeddings = model.node_embeddings[0]\n",
    "second_embeddings = model.node_embeddings[1]\n",
    "concat_embeddings = np.append(first_embeddings, second_embeddings, axis=0)\n",
    "\n",
    "first_embeddings_red = dim_reduction(first_embeddings[:,:6], algorithm=algorithm, n_components=n_components)\n",
    "second_embeddings_red = dim_reduction(second_embeddings[:,:6], algorithm=algorithm, n_components=n_components)\n",
    "concat_embeddings_red = dim_reduction(concat_embeddings[:,:6], algorithm=algorithm, n_components=n_components)\n",
    "\n",
    "mtx1, mtx2, disparity = procrustes(first_embeddings_red, second_embeddings_red)\n",
    "\n",
    "plot_embeddings(mtx1, color_type='numeric', color = n2v2r_borda_ranking_pd.loc[node_names,'borda_ranks'], names=node_names)\n",
    "plot_embeddings(mtx2, color_type='numeric', color = n2v2r_borda_ranking_pd.loc[node_names,'borda_ranks'], names=node_names)\n",
    "\n",
    "num_nodes = first_embeddings_red.shape[0]\n",
    "color_one = np.zeros(num_nodes)\n",
    "color_two = np.ones(num_nodes)\n",
    "color_concat = np.append(color_one, color_two, axis=0)\n",
    "\n",
    "plot_embeddings(concat_embeddings_red, color=color_concat, names = np.append(node_names,node_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run enrich GSEA\n",
    "from node2vec2rank.post_utils import enrich_gsea, read_gmt\n",
    "from itertools import chain\n",
    "import os\n",
    "\n",
    "save_results = True\n",
    "save_results_notes = ''\n",
    "\n",
    "# read the geneset libraries\n",
    "kegg_pathway_fn = '../data/gene_set_libraries/yeast/KEGG_2018_yeast.gmt'\n",
    "gobp_pathway_fn = '../data/gene_set_libraries/yeast/GO_Biological_Process_2018_yeast.gmt'\n",
    "\n",
    "# network_background or pathway_background for enrichment\n",
    "# network will use the genes in the network only, while pathway will use all the genes in the pathways\n",
    "# network is \"more fair\" but will find less things in small networks\n",
    "background = 'pathway_background'\n",
    "organism = 'yeast'\n",
    "\n",
    "enrich_padj_cutoff = 0.1\n",
    "# take the top k percentage of the ranking for enrichment\n",
    "top_k_percent = 5\n",
    "\n",
    "if background == 'network_background':\n",
    "    kegg_background = n2v2r_ranking_pd.index.to_list()\n",
    "    gobp_background = n2v2r_ranking_pd.index.to_list()\n",
    "elif background == 'pathway_background':\n",
    "    kegg_dict = read_gmt(kegg_pathway_fn)\n",
    "    kegg_background = list(set(chain.from_iterable(kegg_dict.values())))\n",
    "    gobp_dict = read_gmt(gobp_pathway_fn)\n",
    "    gobp_background = list(set(chain.from_iterable(gobp_dict.values())))\n",
    "else:\n",
    "    raise Exception(\"Enrichment background not properly set\")\n",
    "\n",
    "n2v2r_enr_KEGG_pd = enrich_gsea(n2v2r_ranking_pd, kegg_pathway_fn, background=kegg_background,\n",
    "                                          enrich_padj_cutoff=enrich_padj_cutoff, enrich_quantile_cutoff=1-top_k_percent/100, organism=organism)\n",
    "\n",
    "n2v2r_enr_GOBP_pd = enrich_gsea(n2v2r_ranking_pd, gobp_pathway_fn, background=gobp_background,\n",
    "                                          enrich_padj_cutoff=enrich_padj_cutoff, enrich_quantile_cutoff=top_k_percent/100, organism=organism)\n",
    "\n",
    "borda_enr_KEGG_pd = enrich_gsea(n2v2r_borda_ranking_pd, kegg_pathway_fn, background=kegg_background,\n",
    "                                enrich_padj_cutoff=enrich_padj_cutoff, enrich_quantile_cutoff=1-top_k_percent/100, organism=organism)\n",
    "\n",
    "borda_enr_GOBP_pd = enrich_gsea(n2v2r_borda_ranking_pd, gobp_pathway_fn, background=gobp_background,\n",
    "                                enrich_padj_cutoff=enrich_padj_cutoff, enrich_quantile_cutoff=1-top_k_percent/100, organism=organism)\n",
    "\n",
    "absDeDi_enr_KEGG_pd = enrich_gsea(DeDi_data_pd[['absDeDi']], kegg_pathway_fn, background=kegg_background,\n",
    "                                  enrich_padj_cutoff=enrich_padj_cutoff, enrich_quantile_cutoff=1-top_k_percent/100, organism=organism)\n",
    "\n",
    "absDeDi_enr_GOBP_pd = enrich_gsea(DeDi_data_pd[['absDeDi']], gobp_pathway_fn, background=gobp_background,\n",
    "                                  enrich_padj_cutoff=enrich_padj_cutoff, enrich_quantile_cutoff=1-top_k_percent/100, organism=organism)\n",
    "\n",
    "if save_results:\n",
    "    path = '../results/results_gsea/' + gsea_parent_folder_name\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        os.makedirs(path)\n",
    "\n",
    "    n2v2r_enr_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                                       \"_n2v2r\"+\"_consensus_enr_KEGG_\"+background+\"_top\"+str(top_k_percent)+\"_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    n2v2r_enr_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                                       \"_n2v2r\"+\"_consensus_enr_GOBP_\"+background+\"_top\"+str(top_k_percent)+\"_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    borda_enr_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target+\"_n2v2r\" +\n",
    "                             \"_borda_enr_KEGG_\"+background+\"_top\"+str(top_k_percent)+\"_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    borda_enr_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target+\"_n2v2r\" +\n",
    "                             \"_borda_enr_GOBP_\"+background+\"_top\"+str(top_k_percent)+\"_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    absDeDi_enr_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                               \"_absDeDi\"+\"_enr_KEGG_\"+background+\"_top\"+str(top_k_percent)+\"_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    absDeDi_enr_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                               \"_absDeDi\"+\"_enr_GOBP_\"+background+\"_top\"+str(top_k_percent)+\"_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run prerank GSEA\n",
    "from node2vec2rank.post_utils import prerank_gsea\n",
    "\n",
    "save_results = True\n",
    "save_results_notes = ''\n",
    "\n",
    "# read the geneset libraries\n",
    "kegg_pathway_fn = '../data/gene_set_libraries/yeast/KEGG_2018_yeast.gmt'\n",
    "gobp_pathway_fn = '../data/gene_set_libraries/yeast/GO_Biological_Process_2018_yeast.gmt'\n",
    "\n",
    "prerank_padj_cutoff = 0.25\n",
    "prerank_weight = 0\n",
    "prerank_min_path_size = 5\n",
    "prerank_max_path_size = 1500\n",
    "prerank_num_perms = 1000\n",
    "\n",
    "n2v2r_pre_KEGG_pd = prerank_gsea(n2v2r_ranking_pd, kegg_pathway_fn, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                           prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "n2v2r_pre_GOBP_pd = prerank_gsea(n2v2r_ranking_pd, gobp_pathway_fn, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                           prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "borda_pre_KEGG_pd = prerank_gsea(n2v2r_borda_ranking_pd, kegg_pathway_fn, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                 prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "borda_pre_GOBP_pd = prerank_gsea(n2v2r_borda_ranking_pd, gobp_pathway_fn, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                 prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "absDeDi_pre_KEGG_pd = prerank_gsea(DeDi_data_pd[['absDeDi']], kegg_pathway_fn, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                   prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "absDeDi_pre_GOBP_pd = prerank_gsea(DeDi_data_pd[['absDeDi']], gobp_pathway_fn, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                   prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "DeDi_pre_KEGG_pd = prerank_gsea(DeDi_data_pd[['DeDi']], kegg_pathway_fn, one_sided=False, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "DeDi_pre_GOBP_pd = prerank_gsea(DeDi_data_pd[['DeDi']], gobp_pathway_fn, one_sided=False, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "n2v2r_borda_DeDi_pre_KEGG_pd = prerank_gsea(n2v2r_borda_DeDi_ranking_pd, kegg_pathway_fn, one_sided=False, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "n2v2r_borda_DeDi_pre_GOBP_pd = prerank_gsea(n2v2r_borda_DeDi_ranking_pd, gobp_pathway_fn, one_sided=False, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "n2v2r_DeDi_pre_KEGG_pd = prerank_gsea(n2v2r_DeDi_ranking_pd, kegg_pathway_fn, one_sided=False, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "n2v2r_DeDi_pre_GOBP_pd = prerank_gsea(n2v2r_DeDi_ranking_pd, gobp_pathway_fn, one_sided=False, prerank_padj_cutoff=prerank_padj_cutoff, prerank_weight=prerank_weight,\n",
    "                                prerank_min_path_size=prerank_min_path_size, prerank_max_path_size=prerank_max_path_size, prerank_num_perms=prerank_num_perms, num_threads=n_cores)\n",
    "\n",
    "if save_results:\n",
    "    path = '../results/results_gsea/' + gsea_parent_folder_name\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        os.makedirs(path)\n",
    "\n",
    "    n2v2r_pre_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                                       \"_n2v2r\"+\"_consensus_prerank_KEGG_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    n2v2r_pre_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                                       \"_n2v2r\"+\"_consensus_prerank_GOBP_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    borda_pre_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target+\"_n2v2r\" +\n",
    "                             \"_borda_prerank_KEGG_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    borda_pre_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target+\"_n2v2r\" +\n",
    "                             \"_borda_prerank_GOBP_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    absDeDi_pre_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                               \"_absDeDi\"+\"_prerank_KEGG_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    absDeDi_pre_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                               \"_absDeDi\"+\"_prerank_GOBP_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    DeDi_pre_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                            \"_DeDi\"+\"_prerank_KEGG_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    DeDi_pre_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                            \"_DeDi\"+\"_prerank_GOBP_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    n2v2r_borda_DeDi_pre_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                            \"_n2v2r_borda_DeDi\"+\"_prerank_KEGG_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    n2v2r_borda_DeDi_pre_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                            \"_n2v2r_borda_DeDi\"+\"_prerank_GOBP_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    n2v2r_DeDi_pre_KEGG_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                            \"_n2v2r_chimera\"+\"_prerank_KEGG_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n",
    "    n2v2r_DeDi_pre_GOBP_pd.to_csv(path+\"/\"+tissue+\"_\"+network_inf_method+\"_\"+target +\n",
    "                            \"_n2v2r_chimera\"+\"_prerank_GOBP_\"+save_results_notes+\".tsv\", header=True, index=None, sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "node2vec2rank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "177e2573c35447d5c54e30f63e196616e0e86c4bc86471ca094a5fa340271d71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
